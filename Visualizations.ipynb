{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘repr’ was built under R version 3.3.2”Warning message:\n",
      "“package ‘rgl’ was built under R version 3.3.2”"
     ]
    }
   ],
   "source": [
    "# Install and load a few useful packages\n",
    "# corrplot:    for making a pretty heatmap of the sample correlation matrix\n",
    "# repr:        for adjusting plot dimensions in jupyter notebook\n",
    "# MASS:        for multidimensional scaling\n",
    "# rgl:  for Swiss Roll dataset + nonlinear dimensionality reduction\n",
    "\n",
    "installed <- installed.packages()\n",
    "if (!\"corrplot\" %in% installed) {install.packages(\"corrplot\")}\n",
    "if (!\"MASS\" %in% installed) {install.packages(\"MASS\")}\n",
    "if (!\"repr\" %in% installed) {install.packages(\"repr\")}\n",
    "if (!\"rgl\" %in% installed) {install.packages(\"rgl\")}\n",
    "\n",
    "library(\"corrplot\")\n",
    "library(\"MASS\")\n",
    "library(\"repr\") \n",
    "library(\"rgl\")\n",
    "\n",
    "# seed the rng for reproducibility\n",
    "set.seed(94608)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We list a few visualizations that may be helpful when exploring high-dimensional datasets. Additional techniques are discussed in the accompanying [Factor Analysis in R](./Factor Analysis in R.ipynb) and [Factor Analysis Theory](./Factor Analysis Theory.ipynb) notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load dataset of wine properties\n",
    "d = read.table(\"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\", sep=',')\n",
    "colnames(d) = c(\"type\",\t\"alcohol\", \"malic\", \"ash\", \"alcalinity\", \"magnesium\", \"phenols\", \"flavanoids\", \"nonflavanoids\", \"proanthocyanins\", \"color\", \"hue\", \"dilution\", \"proline\")\n",
    "d$type <- as.factor(d$type)\n",
    "\n",
    "# standardize all numeric columns data by subtracting column means (centering) \n",
    "# and dividing by the standard deviation (scaling)\n",
    "ind = sapply(d, is.numeric)\n",
    "d[ind] = lapply(d[ind], scale)\n",
    "\n",
    "# inspect the standardized dataset\n",
    "head(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Matrix\n",
    "This technique allows you to quickly you visualize the pairwise correlations between each dimension in your dataset. We used it in the [Factor Analysis in R](./Factor Analysis in R.ipynb) notebook to look at the correlations between different personality dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at the correlations between dimensions in the wine dataset\n",
    "corrplot(cor(d[,-1]), order = \"hclust\", tl.col='black', tl.cex=.75, type=\"upper\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatterplots and Multidimensional Scaling\n",
    "Multidimensional scaling (MDS) is an approach to dimensionality reduction based on pairwise dissimilarities (\"distances\") between dimensions. Roger Shepard famously introduced nonmetric MDS in his search for a [universal law of generalization](http://smash.psych.nyu.edu/courses/spring16/learnmem/papers/Shepard1987.pdf).\n",
    "\n",
    "Brief descriptions:\n",
    "- **Classic MDS**: Given a distance matrix, find a lower-dimensional embedding that preserves pairwise distances as accurately as possible. Performed using the `cmdscale` function in the `MASS` package. Produces the same results as PCA. \n",
    "- **Non-metric MDS**: An iterative, non-linear method. Given a distance matrix, attempts to find a lower-dimensional embedding that preserves the _relative ordering_ of the pairwise distances as closely as possible. Performed using the `isoMDS` function in the `MASS` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adjust plotting options\n",
    "options(repr.plot.width=10, repr.plot.height=4)\n",
    "wine.par = par(mfrow=c(1, 3), pty=\"s\")\n",
    "\n",
    "# perform classic (metric) MDS with k=2 latent dimensions\n",
    "# observe that this produces the same solution as PCA\n",
    "mds = cmdscale(dist(d), k=2)\n",
    "plot(mds, col=d$type, pch=16, main='Metric MDS', xlab='Dim 1', ylab='Dim 2')\n",
    "legend(\"bottomright\", legend=c(\"Wine Type 1\", \"Wine Type 2\", \"Wine Type 3\"), \n",
    "       fill=c(\"black\", \"red\", \"green\"), bty='n', cex=0.65)\n",
    "\n",
    "# perform non-metric MDS for k=2 latent dimensions\n",
    "mds = isoMDS(dist(d), k=2)\n",
    "plot(mds$points, col=d$type, pch=16, main='Non-Metric MDS', xlab='Dim 1', ylab='Dim 2')\n",
    "legend(\"bottomright\", legend=c(\"Wine Type 1\", \"Wine Type 2\", \"Wine Type 3\"), \n",
    "       fill=c(\"black\", \"red\", \"green\"), bty='n', cex=0.65)\n",
    "\n",
    "# Compare MDS against results found using top 2 principal components\n",
    "pca = prcomp(d[,-1])\n",
    "plot(pca$x[,1:2], col=d[,1], pch=16, main=\"PCA\")\n",
    "legend(\"bottomright\", legend=c(\"Wine Type 1\", \"Wine Type 2\", \"Wine Type 3\"), \n",
    "       fill=c(\"black\", \"red\", \"green\"), bty='n', cex=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biplots (PCA)\n",
    "`biplot` in the `stats` package can be useful when trying to interpret the output of PCA. In a biplot, the red vectors correspond to the dimensions from the original dataset, projected into the subspace spanned by the first two principal components. The length of each vector represents the strength of the correlation between the original data dimension and the principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=10, repr.plot.height=7)\n",
    "biplot(pca, xlabs = rep(\"\", nrow(d)), main=\"Wine PCA Biplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scree Plots\n",
    "Scree plots are useful when trying to determine the number of components/factors/latent dimensions to use in your dimensionality reduction regimen. Here, we use a scree plot to identify the number of principal components which capture the most variance in the wine dataset. Visually, it appears that the elbow of the plot occurrs around 4 PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=6, repr.plot.height=4)\n",
    "plot(pca, type='l', main='Wine PCA Scree Plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# here's a convenient function for displaying slightly more detailed scree plots\n",
    "# credit: https://rstudio-pubs-static.s3.amazonaws.com/27823_dbc155ba66444eae9eb0a6bacb36824f.html\n",
    "pcaCharts <- function(x) {\n",
    "    options(repr.plot.width=10, repr.plot.height=7)\n",
    "    x.var <- x$sdev ^ 2\n",
    "    x.pvar <- x.var/sum(x.var)\n",
    "    print(\"Proportion of variance:\")\n",
    "    print(x.pvar)\n",
    "    \n",
    "    par(mfrow=c(2,2))\n",
    "    plot(x.pvar,xlab=\"Principal component\", ylab=\"Proportion of variance explained\", ylim=c(0,1), type='b')\n",
    "    plot(cumsum(x.pvar),xlab=\"Principal component\", ylab=\"Cumulative Proportion of variance explained\", ylim=c(0,1), type='b')\n",
    "    screeplot(x)\n",
    "    screeplot(x,type=\"l\")\n",
    "    par(mfrow=c(1,1))\n",
    "}\n",
    "\n",
    "pcaCharts(pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nonlinear Approaches: The importance of visualization\n",
    "This example is meant to illustrate the importance of visualizing the fit of your dimensionality reduction method. Here we'll use a dataset from the ML community known as the \"Swiss Roll dataset.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SwissRoll <- function(N=2000, Height=30, Plot=FALSE){\n",
    "    # credit: https://github.com/Bioconductor-mirror/RDRToolbox/blob/master/R/SwissRoll.R\n",
    "    ## build manifold\n",
    "    p = (3 * pi / 2) * (1 + 2 * runif(N, 0, 1));  \n",
    "    y = Height * runif(N, 0 , 1);\n",
    "    samples = cbind(p * cos(p), y, p * sin(p));\n",
    "\n",
    "    ## plot and return samples\n",
    "    if(Plot){\n",
    "        ## load rgl for three dimensional plots\n",
    "        if(!require(rgl))\n",
    "           stop(\"package rgl required for three dimensional plots\")\n",
    "    }else{\n",
    "        \tplot3d(samples, xlab=\"x\", ylab=\"y\", zlab=\"z\");\n",
    "    }\n",
    "    return(samples)\n",
    "\n",
    "}\n",
    "\n",
    "sr = SwissRoll(Plot=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
